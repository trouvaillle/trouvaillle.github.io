---
layout: post
title: "AI Engineering: Chapter 7, 8"
date: 2025-03-02 12:00:00 +0900
categories: study ai-engineering
comments: true
visible: true
---
[AI Engineering by Chip Huyen](https://www.oreilly.com/library/view/ai-engineering/9781098166298/)

## Chapter 7
Finetuning: 파인튜닝

- <mark>파인튜닝은 모델의 전체 또는 일부를 추가적으로 학습시켜서 특정 작업에 적응<small>adapt</small>시키는 과정을 말한다.</mark>
    - 모델의 가중치를 조정한다.
- 모델의 도메인 특화 기능을 향상시킬 수 있다.
    - 코딩이나 의학 질의응답
- 모델의 안전성을 강화할 수 있다.
- 대부분 모델의 지시 수행 능력을 향상시키는데 사용된다. 특히 특정 출력 스타일이나 형식에 준수하도록 하기 위해 활용된다.
- 언제 파인튜닝 또는 RAG를 해야할지는 흔한 질문이다.
- 프롬프트 기반 방법과 다르게 <mark>파인튜닝은 훨씬 많은 메모리 발자국</mark>을 유발한다.
    - 많은 파인튜닝 기술들은 메모리 요구량을 줄이는 것에 착안하여 개발됐다.
- <mark><i>PEFT</i><small>parameter-efficient finetunig</small>는 메모리 효율적인 접근</mark>으로 파인튜닝 영역에서 지배적이되었다.
    - PEFT에서는 특히 adpater-based 기술을 살펴본다.

### 파인튜닝 개요
- 파인튜닝은 필요한 능력을 가진 베이스 모델로 시작한다.
- <mark>파인튜닝의 목표는 베이스 모델을 특정 작업을 더 잘 수행하도록 만드는 것이다.</mark>
- 파인튜닝은 전이 학습<small>transfer learning</small>의 한 방법이다.
    - 전이 학습은 Bozinov‐ski와 Fulgosi에 의해 1976년 처음 소개되었다.
    - 전이 학습은 한 작업에서 얻어진 지식을 새로운 작업의 학습 가속을 위해 전이하는 방법에 집중한다.
    - 피아노를 칠 줄 아는 사람이 다른 악기를 더 쉽게 다루는 것과 비슷하다.
- 딥러닝 초창기 동안 전이 학습은 제한되거나 값비싼 훈련 데이터를 지닌 작업에 대한 해결책을 제시했다.
- LLM에서 텍스트 완성을 위한 사전 학습에서 얻어진 지식은 특화된 작업인 법률 질의응답이나 text-to-SQL로 전이될 수 있다.
    - 전이 학습의 능력은 파운데이션 모델을 더 가치있게 만들 수 있다.
- <mark>전이 학습은 샘플 효율성<small>sample efficiency</small>를 향상시키고 모델은 더 적은 예제로 같은 행동을 효과적으로 배우게 할 수 있다.</mark>
    - 예를 들어, 법률 질의응답 모델을 처음부터 만드려면 100만개의 예제가 필요하겠지만, 좋은 베이스 모델을 파인튜닝할 때는 수백개의 예제로 충분하다.
- <mark>이상적으로 보면, 모델이 배워야 할 많은 내용은 이미 베이스 모델에 포함되어 있으며, 파인튜닝은 모델의 행동을 다듬는 역할을 한다.</mark>
    - OpenAI의 [InstructGPT (2022)](https://arxiv.org/abs/2203.02155)에서는 모델이 이미 가지고 있으나 사용자들이 프롬프팅만으로는 접근하기 어려운 능력을 파인튜닝이 잠금 해제한다는 관점을 제안한다.
<aside mark="💡">
전이 학습은 파인튜닝 뿐만 아니라 특징 기반 전이<small>feature-based transfer</small>로도 가능하다.<br/>
특징 기반 전이에서는 모델이 데이터로부터 특징을 추출하고 다른 모델에서 이를 이용한다.<br/>
특징 기반 전이의 예로, 파운데이션 모델은 분류 헤드<small>classifier head</small>를 추가하여 분류 작업에 재사용될 수 있다.
</aside>
- 파인튜닝은 모델 학습 과정의 일부이며, 사전 학습의 확장이다.
    - 파인튜닝은 사전 학습 이후의 모든 훈련을 의미한다.
- 모델 훈련 과정은 사전 학습으로 시작되며 자기 지도<small>self-supervision</small>로 이루어진다.
    - 자기 지도는 모델이 레이블되지 않은 다량의 데이터로부터 학습할 수 있도록 한다.
    - 언어 모델에서 자기 지도 데이터는 주석이 필요없는 텍스트의 나열을 의미한다.
- <mark>값비싼 작업 특화 데이터로 파인튜닝하기 전에, 저렴한 작업 연관 데이터로 자기 지도 파인튜닝을 할 수 있다.</mark>
    - 예를 들어, 법률 질의응답의 경우 날 것의 법률 문서로 파인튜닝할 수 있다.
    - 모델이 베트남어로 책 요약을 하도록 파인튜닝하려면 많은 베트남어 텍스트로 먼저 인튜닝할 수 있다.
- 자기 지도 파인튜닝<small>self-supervised finetuning</small>은 연속 사전 학습<small>continued pre-traning</small>이라고도 불린다.
- 지도 파인튜닝<small>supervised finetuning</small>을 통해 모델이 다음 토큰이나 빈 칸을 채우도록 파인튜닝할 수 있다.
    - 후자는 빈 칸 채우기 파인튜닝<small>infilling finetuning</small>이며 텍스트 편집이나 코드 디버깅 같은 작업에 특히 유용하다. 
    - 모델이 자기회귀적<small>autoregressively</small>으로 사전 학습되었더라도 빈 칸 채우기 파인튜닝을 할 수 있다.
- <mark>지도 파인튜닝은 고품질의 주석이 달린 데이터를 사용하여 모델을 인간의 사용 방식과 선호도에 맞게 다듬는다.</mark>
- <mark>지도 파인튜닝 동안 모델은 (입력, 출력) 쌍으로 훈련된다.</mark>
    - 입력은 지시, 출력은 답변이 될 수 있다.
- 답변은 책 요약처럼 열린 결말<small>open-ended</small>이거나 분류 작업처럼 닫힌 결말<small>close-ended</small>일 수 있다.
- 고품질 지시 데이터는 만들기 어렵고 비쌀 수 있다. 특히 사실적 일관성, 도메인 전문가, 정치적 올바름을 요구하는 지시일 경우 더 그렇다.
- <mark>모델은 사람의 선호도를 최대화할 수 있는 답변을 생성하도록 강화 학습으로 파인튜닝될 수 있다.</mark>
    - <mark>선호도 파인튜닝<small>preference finetuning</small>은 주로 (지시, 이긴 답변, 진 답변)의 형식을 따르는 비교 데이터를 필요로 한다.</mark>
- <mark>컨텍스트 길이를 늘리기 위해 모델을 파인튜닝할 수 있다.</mark>
    - 긴 컨텍스트 파인튜닝<small>long-context finetuning</small>은 주로 모델의 구조를 수정할 필요가 있다. 일례로, 위치 임베딩<small>positional embedding</small>을 조정해야 한다.
    - 긴 시퀀스는 토큰이 더 많은 가능한 위치를 가진다는 것이고, 위치 임베딩은 이를 처리할 수 있어야 한다.
    - 긴 컨텍스트 파인튜닝은 다른 파인튜닝보다 수행하기 어렵고, 결과 모델은 짧은 시퀀스에 대해 품질이 저하될 수 있다.
- 모델 개발자는 다른 목적으로 파인튜닝된 여러 모델 버전을 출시할 수 있으며, 애플리케이션 개발자는 적합한 모델을 선택할 수 있다.

<div style="text-align: center;"><img src="{{ "/assets/img/posts/study/ai-engineering/chapter7-8/figure7-1.png" | relative_url }}" width="540px"/><p>Code Llama 모델에 적용된 여러 파인튜닝 기술들</p></div>

### 언제 파인튜닝을 해야할까?
파인튜닝과 프롬프팅은 상호 배타적인 접근이 아니라, 현실 세계의 문제를 풀기 위해 종종 함께 사용되어야 한다.

#### 파인튜닝할 이유
- 파인튜닝할 주된 이유는 모델의 품질을 향상시키기 위함이다.<br/>
    여기서 품질이란 전반적인 모델의 능력과 작업 특화적인 능력을 의미한다.

- 특히 흥미로운 파인튜닝 용례는 편견 제거다. 베이스 모델이 훈련 데이터로부터 어떤 편견을 영속하고 있으면, 세심하게 선정된 데이터를 노출시키는 방식으로 파인튜닝을 진행하면 해당 편견을 상쇄시킬 수 있다.
    - [Garimella et al. (2022)](https://aclanthology.org/2022.aacl-short.38/)는 여성이 작성한 글이 모델의 성별 편견을 제거하고, 아프리칸 작성자가 쓴 글이 인종 편견을 제거할 수 있음을 발견했다.
- 공통적인 접근 방법을 <mark>더 큰 모델로부터 생성된 데이터를 통해 더 큰 모델의 행동을 작은 모델이 모방하도록 파인튜닝하는 것이다.</mark>
    - *증류<small>distillation</small>*라는 방법으로 대형 모델의 지식을 작은 모델로 증류하는 접근 방법이다.
- <mark>특정 작업에 대해 파인튜닝된 작은 모델은 가끔 훨씬 큰 초기 상태의 모델보다 해당 작업을 잘 수행할 수 있다.</mark>

#### 파인튜닝하지 않을 이유
- 파인튜닝은 모델의 성능을 향상시킬 수 있지만 <mark>섬세하게 작성된 프로픔프트와 컨텍스트도 성능 향상에 기여할 수 있다.</mark>
- 먼저, <mark>모델을 특정 작업에 파인튜닝하면 해당 작업에 대한 성능을 향상시킬 수 있지만, 다른 작업에 대한 성능을 약화시킬 수 있다.</mark>
이런 경우 서로 다른 작업에 분리된 모델을 사용하는 것을 고려해볼 수 있다.
    - 프로젝트를 위한 실험의 시작으로 파인튜닝을 사용하기는 어렵다. 파인튜닝에는 먼저 데이터가 필요하고, 주석처리된 데이터는 수동으로 얻기에 느리고 비싸다. 특히 비판적 사고와 도메인 전문 지식을 요구하는 작업의 경우 더 그렇다. 오픈 소스 데이터와 AI로 생성된 데이터가 비용을 줄여줄 수 있지만, 그 효과성은 매우 변동적이다.
- 두번째로, 파인튜닝은 모델을 훈련하는 방법에 대한 지식을 필요로 한다. 
- 세번째로, 모델을 파인튜닝했다면 어떻게 서빙해야할지 결정해야한다.
    - 모니터링, 유지보수, 모델 업데이트에 대한 정책과 예산을 수립해야한다.<br/><mark>베이스 모델은 당신이 파인튜닝한 모델을 개선하는 속도보다 빠르게 개선될 수 있다.</mark>
- 많은 경우에 나은 모델로 교체하는 것은 성능 향상에 있어 매우 작은 부분만 제공한다.
- <mark>AI 엔지니어링 실험은 프롬프팅으로 시작되어야 한다.</mark>
    - 모델의 성능은 서로 다른 프롬프트에 따라 매우 크게 다를 수 있다.
- 프롬프트가 비효율적이라고 주장하고 파인튜닝의 정당성을 주장한 많은 경우, 프롬프트 실험이 최소화되고 체계적이지 않았다. 지시가 불명확하고, 예제가 실제 데이터를 대표하지 않고, 지표가 어설프게 정의되었다. <mark>프롬프트 실험 과정을 정교화하고나서는 프롬프트 품질이 해당 사례의 애플리케이션에 충분할 정도로 향상되었다.</mark>
- 파인튜닝을 주장하는 엔지니어 중 몇은 단지 파인튜닝을 배우고 싶은 경우가 있다.
    - 리더십 위치라면 파인튜닝이 정말 필요한 것인지 단지 하고 싶은것인지 구별하기 어렵다.

<aside mark="💡">
도메인 특화 작업 파인튜닝하기
<ul>
<li>범용 모델의 능력이 향상될 수록 도메인 특화 작업에 도메인 특화 모델보다 나은 성능을 보이고 있다.</li>
<li>도메인 특화 모델인 BloombergGPT(March 2023)를 범용 모델인 GPT-4-0314가 훨씬 능가한 경우가 있다.</li>
</ul>

<div style="text-align: center;"><img src="{{ "/assets/img/posts/study/ai-engineering/chapter7-8/table7-1.png" | relative_url }}" width="540px"/></div>

</aside>
- 파인튜닝과 프롬프트 실험 모두 체계적 과정이 필요하다. 프롬프트 실험을 수행하는 것은 개발자가 평가 파이프라인, 데이터 주석 가이드라인 및 실험 추적 관행을 구축할 수 있게 하며, 이는 파인튜닝을 위한 디딤돌이 될 것이다.
- 파인튜닝의 한가지 이점은 토큰 사용을 취적화하는데 도움이 된다는 것이다. 이는 프롬프트 캐싱이 소개되기전까지 유효했다.
    - <mark>매 프롬프트마다 예제를 포함하지 않고, 해당 예제들로 모델을 파인튜닝할 수 있다.</mark> 이는 파인튜닝한 모델을 더 짧은 프롬프트로 사용할 수 있게 한다.
- 프롬프트 캐싱을 사용하면, 반복적인 프롬프트 구문은 재사용을 위해 캐시될 수 있어서 강력한 이점이 되지는 못한다.
- 프롬프트에 제공할 수 있는 예제의 수는 최대 컨텍스트 길이에 제한된다.
    - <mark>파인튜닝을 이용하면, 사용할 수 있는 예제의 수에 제한이 없다.</mark>

<div style="text-align: center;"><img src="{{ "/assets/img/posts/study/ai-engineering/chapter7-8/figure7-2.png" | relative_url }}" width="540px"/></div>

#### 파인튜닝과 RAG
- 프롬프트로부터 가능한 성능 향상을 최대화하고나서는 RAG나 파인튜닝 중 어떤 걸 시도할 지 고민할 수 있다. <mark>이는 모델의 실패가 정보<small>information-based</small> 또는 행동<small>behavior-based</small>에 기인한 것인지에 따라 다르다.</mark>
- 모델이 정보 부족으로 실패한다면 모델이 연관 된 정보의 출처에 접근할 수 있도록하는 RAG 시스템이 도움을 줄 수 있다. 정보에 기인한 실패는 출력이 사실적으로 틀렸거나 기한이 지났을 경우 발생한다. 
    - 정보 부족
        - 공개 모델은 당신 조직의 사적 정보를 포함하고 있지 않다.
    - 기한 지난 정보
        - Taylor Swift의 앨범수를 물어볼 경우 모델의 cut-off 날짜에 따라 다르게 응답할 수 있따.
- [Fine-Tuning or Retrieval?](https://arxiv.org/pdf/2312.05934)에 따르면 <mark>최신 정보가 필요한 작업의 경우 파인튜닝 모델보다 RAG가 더 나은 성능을 보였다.</mark> 또한, 베이스 모델을 통한 RAG가 파인튜닝 모델을 통한 RAG보다 나은 성능을 보였다. 이는 파인튜닝은 특정 작업에 모델의 성능을 향상시킬 수 있지만, 다른 분야에 대한 성능을 약화시킬 수 있다는 것을 시사한다.
- <mark>모델이 행동 문제가 있다면 파인튜닝이 도움이 될 수 있다.</mark>
    - 행동 문제 예시는 모델의 출력이 사실적으로 맞지만 작업에 부적절한 경우다.
- 다른 문제는 예상한 출력 형식을 모델이 따르지 못하는 경우다.
    - 의미적 파싱<small>semantic parsing</small>은 자연어를 JSON같은 구조화 형식으로 변환하는 걸 의미한다.
- 요약하자면 <mark>파인튜닝은 형식을 위해, RAG는 사실을 위해 실시한다.</mark>
    - RAG 시스템은 모델에 외부 지식을 제공해 더 정확하고 정보가 풍부한 답변을 생성할 수 있게 한다.
    - RAG 시스템은 모델의 할루시네이션 제거에 도움을 줄 수 있다.
    - 파인튜닝은 모델이 문법과 형식을 이해하고 따를 수 있도록 하는 데 도움을 준다.
    - 파인튜닝도 할루시네이션을 줄일 수 있다. 이는 데이터 품질이 좋을 때만이고, 저품질 데이터는 할루시네이션을 악화시킬 수 있다.
- <mark>모델이 정보과 행동 문제를 모두 가지고 있다면 RAG으로 시작하라.</mark>
- <mark>RAG을 진행할 때, BM25 용어 기반 방법을 먼저 시도한다.</mark> 벡터 데이터베이스를 필요로하는 방법은 나중이다.
- <mark>RAG은 파인튜닝보다 더 큰 성능 향상을 가져올 수 있다.</mark>
- RAG와 파인튜닝은 상호 배타적이지 않고, 애플리케이션 성능의 최대화를 위해 함께 사용되기도 한다.
    - [Ovadia et al. (2024)](https://arxiv.org/pdf/2312.05934)는 파인튜닝 모델 위에 RAG를 사용하는 것은 MMLUE 벤치마크에서 성능 향상을 보인 경우를 포함한다.
    - 57%의 경우 RAG만 사용한 경우에 비해 파인튜닝과 RAG를 함께 사용한 경우보다 성능 향상을 보이지 못했다.

<div style="text-align: center;"><img src="{{ "/assets/img/posts/study/ai-engineering/chapter7-8/figure7-3.png" | relative_url }}" width="540px"/></div>

- 모델의 적응 과정은 아래처럼 요약할 수 있다.
    1. 프롬프트만으로 작업을 수행할 수 있는 모델을 구하려고 시도한다. 프롬프팅 시 체계적인 버전 관리를 수행한다.
    2. 프롬프트에 예제를 더 추가한다. 예제는 대개 1에서 50개 정도다.
    3. 정보 부족으로 자주 실패하면 RAG를 도입하고, 용어 기반 검색부터 시도한다. 간단한 조회<small>retrieval</small>만으로도 적절하고 정확한 지식 제공으로 모델의 성능 향상을 이끌 수 있다.
    4. 모델의 실패 방법에 따라 아래를 시도한다.
        1. 정보 부족으로 인한 실패 시 임베딩 기반 검색과 같은 고급 RAG 방법을 RAG에 도입한다.
        2. 행동 문제(부적절하거나 형식이 틀리거나, 불안전한 답변)가 있다면 파인튜닝을 선택할 수 있다. 
            - 임베딩 기반 검색은 추론의 복잡도를 높히는 반면, 파인튜닝은 모델의 개발의 복잡도를 높히고 추론은 유지한다.
    5. RAG와 파인튜닝을 결합해 성능을 더 향상시킨다.

### 메모리 병목
파인튜닝은 메모리 집약적이어서 많은 파인튜닝 기술들이 메모리 발자국을 최소화하는 것을 목표로 하고 있다.

<aside mark="💡">
메모리 병목을 이해하기 위한 핵심 요소
<ol>
<li>파운데이션 모델의 규모로 인해 메모리는 추론과 파인튜닝 모두에 병목이다. 파인튜닝을 위한 메모리 요구는 학습 방법에 의해 추론보다 훨신 크다.</li>
<li>모델의 <mark>메모리 발자국에 크게 기여하는 것은 파라미터 수, 훈련 가능한 파라미터 수 및 숫자 표현<small>numerical representations</small>이다.</mark></li>
<li>훈련 가능한 파라미터 수가 많을 수록 메모리 발자국도 크다. <mark>훈련 가능한 파라미터 수를 줄이려는 것이 PEFT<small>parameter-efficient finetunig</small>의 동기다.</mark></li>
<li><mark>양자화<small>Quantization</small>는 모델을 더 적은 비트의 형식으로 바꾸는 관행을 의미한다.</mark> 양자화는 모델의 메모리 발자국을 줄이는데 간단하고 효율적인 방법이다.</li>
<li>추론은 대개 가능한한 적은 비트 수로 수행된다.(16, 8, 4 bits)</li>
<li>훈련이 수 표현에 더 민감해 적은 정밀도로 모델을 훈련하는 것이 더 어렵다. 훈련은 대개 혼합 정밀도로 수행된다(32-bit와 16-bit 또는 8-bit 혼합).</li>
</ol>
</aside>

#### 역전파와 훈련 가능한 파라미터
- 파인 튜닝의 메모리 사용량에서 핵심 요소는 훈련 가능한 파라미터<small>trainable parameters</small>의 수다. 훈련 가능한 파라미터는 파인튜닝 중 업데이트되는 파라미터를 의미한다.
변하지 않는 파라미터는 고정 파라미터<small>frozen parameters</small>라고 한다.
- 현재 신경망은 대개 역전파<small>backpropagation<small> 메커니즘으로 훈련된다.
    - 역전파는 훈련을 2가지 단계로 구분한다.
        1. 정과정<small>forward pass</small>: 입력으로부터 출력을 계산하는 과정
        2. 역과정<small>backward pass</small>: 정과정으로부터 집계된 신호를 이용해 모델의 가중치를 수정하는 과정
- 추론은 정과정만 수행한다. 훈련은 두 과정 모두 수행한다.
- 거시적 관점에서 역전파는 아래와 같은 작업을 수행한다.
    1. 정과정에서 계산된 출력과 기대 출력(실제 참값)을 비교한다. 두  출력의 차이는 손실<small>loss</small>라 한다.
    2. 각 훈련 가능한 파라미터가 얼마나 실수에 기여했는지 계산한다. 기여도는 그라디언트<small>gradient</small>이라고 한다. 수학적으로 그라디언트는 손실을 각 훈련 가능한 파라미터에 따라 편미분한 값으로 계산된다.
    3. 훈련 가능한 파라미터를 각 그라디언트에 따라 조정한다. 각 그라디언트 값에 따라 각 파라미터가 얼마나 재조정되는지는 옵티마이저<small>optimizer</small>에 의해 결정된다. 흔한 옵티마이저는 SGD<small>stochastic gradient descent</small>와 Adam이다. 트랜스포머 기반 모델은 Adam이 현재 가장 많이 쓰이는 옵티마이저다.

#### 메모리 사용량 계산
#### 수 표현<small>Numerical Presentations</small>
#### 양자화<small>Quantization</small>

### 파인튜닝 기술
#### 파라미터 효율적인 파인튜닝<small>Parameter-Efficent Finetuning</small>
#### 모델 병합과 다중 작업 파인튜닝
#### 파인튜닝 전략

### 요약

## Chatper 8
Dateset Engineering: 데이터셋 엔지니어링

### 데이터 선별<small>Data Curation</small>
#### 데이터 품질
#### 데이터 포괄성<small>Data Coverage</small>
#### 데이터 양
#### 데이터 획득과 주석<small>Data Acquistion and Annotation</small>

### 데이터 증강 및 합성
#### 왜 데이터 합성을 할까?
#### 전통적인 데이터 합성 기술
#### AI 기반 데이터 합성
#### 모델 증류<small>Model Distillation</small>

### 데이터 처리
#### 데이터 검사
#### 데이터 중복 제거
#### 데이터 지우기 및 필터
#### 데이터 형식 맞추기

### 요약